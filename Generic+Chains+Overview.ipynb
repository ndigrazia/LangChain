{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "336b9395",
   "metadata": {},
   "source": [
    "# Generic Chains Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcb42ef",
   "metadata": {},
   "source": [
    "## Simple Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b094e82",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "The most elementary type of chain is known as a basic chain, which represents the simplest form of crafting a chain. <br>In this setup, there is only one Language Model (LLM) responsible for receiving an input prompt and using it for generating text.\n",
    "<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b36c04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d7c528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5547ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "436017aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"place\"],\n",
    "    template=\"Best places to visit in {place}?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2477a555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Taj Mahal, Agra\n",
      "2. The Golden Temple, Amritsar\n",
      "3. Red Fort, Delhi\n",
      "4. Meenakshi Temple, Madurai\n",
      "5. Varanasi\n",
      "6. Jaisalmer\n",
      "7. Goa\n",
      "8. Udaipur\n",
      "9. Rishikesh\n",
      "10. Kerala Backwaters\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Run the chain only specifying the input variable.\n",
    "print(chain.run(\"India\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88205e2",
   "metadata": {},
   "source": [
    "## Simple Sequential Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb1850c",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "Sequential Chains involves making a series of consecutive calls to the language model.<br> This approach proves especially valuable when there is a need to utilize the output generated from one call as the input for another call.\n",
    "<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76654563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92f94dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You have to suggest 5 best places to visit in {place}?\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"place\"], \n",
    "    template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77104326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HF_llm= HuggingFaceHub(repo_id = \"google/flan-t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2578b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa350baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4ea5942",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Given a list a places, please estimate the expenses to visit all of them in local currency and also the days needed\n",
    "{expenses}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"expenses\"],\n",
    "    template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61ca518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef315099",
   "metadata": {},
   "outputs": [],
   "source": [
    "expenses_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16e97f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = SimpleSequentialChain(chains=[place_chain, expenses_chain], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98487cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m1. Taj Mahal, Agra\n",
      "2. Golden Temple, Amritsar\n",
      "3. Goa\n",
      "4. Nubra Valley, Ladakh\n",
      "5. Jaisalmer, Rajasthan\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "The estimated expenses to visit all of these places in Indian Rupees (INR) would be approximately 35,000-40,000. It would take around 7-8 days to visit all of these places.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "review = final_chain.run(\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c09bca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
